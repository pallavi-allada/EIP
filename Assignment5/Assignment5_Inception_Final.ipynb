{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5_Inception_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwTsmztA72kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "MOUNT_DIR = '/content/drive'\n",
        "drive.mount(MOUNT_DIR, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxxKJfF9ZNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT_DIR = '/content/drive/My Drive/Colab Notebooks/EIP4'\n",
        "MODELS_DIR = os.path.join(ROOT_DIR, 'saved_models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5tLUHFn_bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUwraFAA74OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# mount gdrive and unzip data\n",
        "!unzip -q \"/content/drive/My Drive/Colab Notebooks/EIP4/Assignment5_Dataset/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5H_hDRE-kxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "import keras\n",
        "from keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ4NKcz0-f-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head(), df.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3awcRa2_T9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat(\n",
        "    [\n",
        "        df[[\"image_path\"]],\n",
        "        pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "        pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "        pd.get_dummies(df.age, prefix=\"age\"),\n",
        "        pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "        pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "        pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "        pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "        pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "    ], \n",
        "    axis = 1\n",
        ")\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTKceKHN_5IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FxRgaQOAU9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation = None): #img_aug=False):\n",
        "        # self.img_aug = img_aug\n",
        "        self.augmentation = augmentation\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "\n",
        "        # if self.img_aug:\n",
        "        #   eraser = get_random_eraser()\n",
        "        #   aug_image_stack = np.stack([eraser(img) for img in image])\n",
        "        if self.augmentation is not None:\n",
        "          image = self.augmentation.flow(image, shuffle=False).next()\n",
        "\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "\n",
        "        # if self.img_aug:\n",
        "        #   return aug_image_stack, target\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdVFpMWTBHzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state=1)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgXv4l01BPtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJlAHafBZEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32, augmentation=ImageDataGenerator(horizontal_flip=True))#img_aug=True)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False) #, img_aug=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjXN8SVlBscJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qob15lumB2Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backbone = InceptionV3(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "# neck = BatchNormalization()(neck) ####\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    # neck = Dropout(0.2)(in_layer)\n",
        "    # neck = Dense(128, activation=\"relu\")(neck)\n",
        "    # neck = BatchNormalization()(neck) ####\n",
        "    neck = Dropout(0.3)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    # neck = BatchNormalization()(neck) ####\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj19cHh7Cvy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze backbone\n",
        "for layer in backbone.layers:\n",
        "\tlayer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C__q4xPtC6P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "\t\"gender_output\": \"binary_crossentropy\",\n",
        "\t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "\t\"age_output\": \"categorical_crossentropy\",\n",
        "\t\"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"pose_output\":\"categorical_crossentropy\",\n",
        "  \"emotion_output\":\"categorical_crossentropy\"\n",
        "\n",
        "}\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "opt = SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    # loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    loss = losses,\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGFxIrXnDljM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8hNIes4DoZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'model_{epoch:03d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDmVQC8CVD-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/EIP4/saved_models/model_020.hdf5')\n",
        "K.set_value(model.optimizer.lr, 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vmTy8ZdWVUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'model2_{epoch:02d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAa5a2NGhkTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/EIP4/saved_models/model2_20.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2orDAy75hXnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.set_value(model.optimizer.lr, 6e-4)\n",
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'e64model_{epoch:02d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hyO41hruCjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/EIP4/saved_models/e64model_09.hdf5')\n",
        "K.set_value(model.optimizer.lr, 6e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0YN_ZY8uOr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=20,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'e64model2_{epoch:02d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znfosxAmuewN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/EIP4/saved_models/e64model_09.hdf5')\n",
        "K.set_value(model.optimizer.lr, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgGB6IUAy_QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.set_value(model.optimizer.lr, 2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txhmVHKVyny8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS_DIR = os.path.join(ROOT_DIR, 'inception_models') \n",
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=30,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'i2e5model_{epoch:03d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKxy7sN1zGaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/EIP4/inception_models/i2e5model_006.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktxusmI2lDWH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnGBKeN9GQat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.set_value(model.optimizer.lr, 1e-5)\n",
        "MODELS_DIR = os.path.join(ROOT_DIR, 'inception_models') \n",
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(MODELS_DIR, 'i1e5model_{epoch:03d}.hdf5'),\n",
        "                save_best_only=True,\n",
        "                verbose=1,\n",
        "            )],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiudDckfGuNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}